{
  "hash": "e3811c3d01604d5268881c30de69199f",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Bayesian–MILP Model for Multi-Tier Supply Chains\"\nsubtitle: \"Integrating Structural Equation Modeling and Customer Satisfaction Optimization\"\nauthor: \"Dr. Daniel A. Olivares Vera\"\ndate: today\n\nabstract: |\n  This paper proposes a Bayesian–MILP model that integrates structural equation\n  modeling (SEM), Bayesian optimization (BO), and mixed-integer linear programming (MILP)\n  for multi-tier supply chains oriented to customer value maximization.\n\nkeywords:\n  - Bayesian Optimization\n  - Structural Equation Modeling\n  - MILP\n  - Supply Chain\n\nformat:\n  html:\n    toc: true\n    number-sections: true\n    code-fold: true\n    code-tools: true\n    theme: cosmo\n    html-math-method:\n      method: mathjax\n      options:\n        tex:\n          tags: ams\n  pdf:\n    toc: true\n    number-sections: true\n    documentclass: article\n    pdf-engine: lualatex\n    geometry: margin=1in\n    fontsize: 12pt\n    include-in-header:\n      text: |\n        \\usepackage{lineno}\n        \\linenumbers\n\nexecute:\n  echo: true\n  warning: false\n  message: false\n  freeze: false\n---\n\n[Download PDF version](index.pdf)\n\n# Introduction\n\nSupply chain network design has traditionally focused on cost minimization,\nservice level maximization, or efficiency optimization under the assumption\nof exogenous demand. However, in multi-tier supply networks, upstream process\ndecisions influence product quality, which in turn affects customer perception,\nsatisfaction, and ultimately demand behavior.\n\nMost network optimization models treat demand as independent of upstream\noperational decisions. At the same time, the structural equation modeling (SEM)\nliterature analyzes latent quality constructs but does not integrate structural\nnetwork optimization decisions. Furthermore, Bayesian Optimization (BO)\napproaches typically focus on parameter tuning without incorporating discrete\nnetwork design decisions.\n\nThis paper proposes a unified framework that integrates:\n\n- Bayesian Structural Equation Modeling (SEM),\n- Endogenous satisfaction-driven demand,\n- Mixed-Integer Linear Programming (MILP) network design,\n- Gaussian Process–based Bayesian Optimization (BO).\n\nThe key idea is that upstream process variables propagate through a latent\nquality structure, influence customer-specific multi-criteria evaluations,\nendogenize demand, and determine optimal supply chain configuration under\nepistemic uncertainty.\n\nThe main contributions of this work are:\n\n1. The integration of Bayesian latent quality modeling into network design.\n2. The formulation of demand as an endogenous function of customer satisfaction.\n3. The coupling of discrete structural decisions with Gaussian Process–based Bayesian Optimization.\n4. A unified algorithm that jointly optimizes structural configuration and economic utility under uncertainty.\n\nThe remainder of the paper is structured as follows. Section 2 presents\nthe overall modeling framework. Section 3 formalizes the Bayesian SEM.\nSections 4–6 develop the satisfaction, utility, and MILP components.\nSection 7 introduces the Bayesian Optimization layer.\nSection 8 presents numerical experiments.\nSection 9 concludes with managerial implications and future research directions.\n\n# Unified Model Architecture\n\nThe proposed framework consists of four interconnected layers:\n\n1. **Process Layer (Multi-tier Network Structure)**  \n   Each supply chain entity $s \\in \\mathcal{S}$ controls a vector of process variables\n   $\\mathbf{X}_s = (x_{s,1}, \\dots, x_{s,J_s})$.\n   These variables represent operational, technological, or quality-related decisions.\n\n2. **Bayesian Latent Quality Layer (SEM)**  \n   Upstream process variables propagate through a latent quality construct:\n\n   $$\n   \\eta_{c,p} = f(\\mathbf{X}; \\boldsymbol{\\beta}) + \\zeta\n   $$ {#eq-quality}\n\n\n   which determines customer-evaluated criteria:\n\n   $$\n   Y_{c,p,k} = \\lambda_k \\eta_{c,p} + \\varepsilon_{c,p,k}\n   $$ {#eq-criteria}\n\n3. **Economic and Network Optimization Layer (MILP)**  \n   Customer satisfaction influences demand, which determines flow decisions\n   $\\mathbf{q}$ and structural activation variables $\\mathbf{z}$ through\n   a mixed-integer linear programming model.\n\n4. **Bayesian Optimization Layer (BO)**  \n   A Gaussian Process surrogate models the expected economic utility:\n\n   $$\n   f(\\boldsymbol{\\theta}) = \\mathbb{E}[U(\\boldsymbol{\\theta})]\n   $$ {#eq-Gaussian}\n\n   and sequentially updates tunable parameters to maximize expected utility.\n\nThese layers form a closed feedback loop:\n\n- Process decisions affect latent quality.\n- Latent quality determines satisfaction.\n- Satisfaction drives endogenous demand.\n- Demand determines optimal network structure.\n- Observed utility updates Bayesian beliefs.\n- Bayesian Optimization adjusts decision parameters.\n\nThis unified architecture allows structural network design under epistemic uncertainty while explicitly incorporating latent quality propagation and customer heterogeneity.\n\n\n# Bayesian Structural Equation Model\n\nLet:\n\n- $c \\in \\mathcal{C}$ denote customers,\n- $p \\in \\mathcal{P}$ denote products,\n- $k \\in \\{1,\\dots,K\\}$ denote evaluation criteria,\n- $s \\in \\mathcal{S}$ denote supply chain entities (tiers, manufacturers, distribution centers).\n\nEach entity $s$ controls a vector of process variables:\n\n$$\n\\mathbf{X}_s = (x_{s,1}, \\dots, x_{s,J_s})\n$$\n\nLet $\\mathbf{X}$ denote the stacked vector of all upstream process variables.\n\n---\n\n## 3.1 Structural Model (Latent Quality Propagation)\n\nLatent quality for product $p$ perceived by customer $c$ is defined as:\n\n$$\n\\eta_{c,p} = \\mathbf{X}^\\top \\boldsymbol{\\beta} + \\zeta_{c,p}\n$$ {#eq-latent}\n\nwhere:\n\n- $\\boldsymbol{\\beta}$ is the vector of structural coefficients,\n- $\\zeta_{c,p} \\sim \\mathcal{N}(0, \\sigma_\\zeta^2)$ captures structural uncertainty.\n\nThis formulation allows upstream process variables across multiple tiers to jointly influence perceived product quality.\n\n---\n\n## 3.2 Measurement Model (Multi-Criteria Evaluation)\n\nEach customer evaluates product $p$ according to $K$ criteria:\n\n$$\nY_{c,p,k} = \\lambda_k \\eta_{c,p} + \\varepsilon_{c,p,k}\n$$ {#eq-measurement}\n\nwhere:\n\n- $\\lambda_k$ are measurement loadings,\n- $\\varepsilon_{c,p,k} \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon_k}^2)$.\n\nThe vector form is:\n\n$$\n\\mathbf{Y}_{c,p} = \\boldsymbol{\\lambda} \\eta_{c,p} + \\boldsymbol{\\varepsilon}_{c,p}\n$$\n\nThis hierarchical formulation allows:\n\n- Correlated multi-criteria perception,\n- Cross-tier influence propagation,\n- Explicit uncertainty quantification.\n\n---\n\n## 3.3 Bayesian Estimation\n\nWe place prior distributions:\n\n$$\n\\boldsymbol{\\beta} \\sim \\mathcal{N}(0, \\sigma_\\beta^2 I)\n$$\n\n$$\n\\lambda_k \\sim \\mathcal{N}(1, \\sigma_\\lambda^2)\n$$\n\n$$\n\\sigma_\\zeta, \\sigma_{\\varepsilon_k} \\sim \\text{Half-Normal}(0,1)\n$$\n\nThe posterior distribution is:\n\n$$\np(\\boldsymbol{\\beta}, \\boldsymbol{\\lambda}, \\sigma_\\zeta, \\sigma_{\\varepsilon} \\mid \\mathbf{Y}, \\mathbf{X})\n\\propto\np(\\mathbf{Y} \\mid \\mathbf{X}, \\boldsymbol{\\beta}, \\boldsymbol{\\lambda})\np(\\boldsymbol{\\beta}) p(\\boldsymbol{\\lambda}) p(\\sigma_\\zeta) p(\\sigma_{\\varepsilon})\n$$\n\nPosterior draws are used to propagate epistemic uncertainty into downstream satisfaction and network optimization decisions.\n\n\n# Customer Satisfaction, Endogenous Demand, and Utility\n\nThis section links the Bayesian SEM outputs (multi-criteria perceptions) to customer satisfaction, demand, and economic utility, enabling the integration with network optimization.\n\n\n\n\n## 4.1 Customer-Specific Satisfaction Aggregation\n\nLet $Y_{c,p,k}$ be the perceived score of product $p$ by customer $c$ on criterion $k$ (from Eq. @eq-measurement).  \nEach customer has a preference-weight vector:\n\n$$\n\\mathbf{w}_c = (w_{c,1},\\dots,w_{c,K}), \\qquad w_{c,k}\\ge 0,\\ \\ \\sum_{k=1}^K w_{c,k}=1\n$$ {#eq-weights}\n\nCustomer satisfaction is defined as the weighted aggregation:\n\n$$\nS_{c,p} = \\sum_{k=1}^K w_{c,k}\\, Y_{c,p,k}\n$$ {#eq-satisfaction}\n\nThis allows heterogeneous priorities across customers (e.g., durability vs. aesthetics).\n\n---\n\n## 4.2 Endogenous Demand as a Function of Satisfaction\n\nWe model demand as an increasing function of satisfaction. A convenient bounded form is the logistic demand response:\n\n$$\nD_{c,p}(\\mathbf{w}_c) \\;=\\; \\bar{D}_{c,p}\\,\\sigma\\!\\left(\\alpha_{c,p}\\left(S_{c,p}-\\tau_{c,p}\\right)\\right),\n\\qquad\n\\sigma(u)=\\frac{1}{1+e^{-u}}\n$$ {#eq-demand}\n\nwhere:\n\n- $\\bar{D}_{c,p}$ is the market potential,\n- $\\alpha_{c,p}>0$ controls sensitivity,\n- $\\tau_{c,p}$ is an acceptance threshold.\n\nBecause $S_{c,p}$ depends on the SEM posterior, $D_{c,p}$ is a random variable.\n\n---\n\n## 4.3 Economic Utility and Cost Structure\n\nLet $q_{c,p}$ denote delivered quantity of product $p$ to customer $c$ (MILP decision).  \nLet $r_{c,p}$ be the unit revenue (or price). The expected economic utility is:\n\n$$\n\\mathbb{E}[U] \\;=\\;\n\\sum_{c\\in\\mathcal{C}}\\sum_{p\\in\\mathcal{P}}\nr_{c,p}\\,\\mathbb{E}\\!\\left[\\min\\{q_{c,p}, D_{c,p}(\\mathbf{w}_c)\\}\\right]\n\\;-\\; C_{\\text{prod}} \\;-\\; C_{\\text{flow}} \\;-\\; C_{\\text{struct}}\n$$ {#eq-utility}\n\nWe decompose total cost as:\n\n$$\nC_{\\text{prod}} = \\sum_{s\\in\\mathcal{S}}\\sum_{p\\in\\mathcal{P}} c^{\\text{prod}}_{s,p}\\, q_{s,p}\n$$\n\n$$\nC_{\\text{flow}} = \\sum_{(i,j)\\in\\mathcal{A}}\\sum_{p\\in\\mathcal{P}} c^{\\text{ship}}_{i,j,p}\\, y_{i,j,p}\n$$\n\n$$\nC_{\\text{struct}} = \\sum_{(i,j)\\in\\mathcal{A}} f_{i,j}\\, z_{i,j}\n$$\n\nwhere:\n\n- $y_{i,j,p}$ is the flow of product $p$ on arc $(i,j)$,\n- $z_{i,j}\\in\\{0,1\\}$ indicates whether link $(i,j)$ is activated,\n- $f_{i,j}$ is the fixed cost of establishing/using link $(i,j)$.\n\n---\n\n## 4.4 Where Bayesian Optimization Enters\n\nDefine the BO decision variables as the customer preference weights:\n\n$$\n\\Theta \\;=\\; \\{\\mathbf{w}_c: c\\in\\mathcal{C}\\}\n$$\n\nsubject to simplex constraints (Eq. @eq-weights). The objective evaluated by BO is the expected utility under the SEM posterior and the MILP optimal response:\n\n$$\nJ(\\Theta) \\;=\\;\n\\max_{z,q,y}\\ \\mathbb{E}[U(z,q,y;\\Theta)]\n\\quad\\text{s.t. MILP constraints}\n$$ {#eq-bo-objective}\n\nBayesian Optimization searches for:\n\n$$\n\\Theta^\\star = \\arg\\max_{\\Theta}\\ J(\\Theta)\n$$ {#eq-bo-opt}\n\nIn practice, the expectation in $J(\\Theta)$ is computed via Monte Carlo using posterior samples from the Bayesian SEM, thereby propagating uncertainty into satisfaction, demand, and network decisions.\n\n# Bayesian Optimization Layer\n\nThe decision vector to be optimized is:\n\n$$\n\\Theta = \\{\\mathbf{w}_c : c \\in \\mathcal{C}\\}\n$$\n\nwhere each $\\mathbf{w}_c$ lies in the probability simplex:\n\n$$\nw_{c,k} \\ge 0, \\qquad \\sum_{k=1}^K w_{c,k} = 1\n$$\n\nThe objective function evaluated by Bayesian Optimization is:\n\n$$\nJ(\\Theta) = \\max_{z,q,y} \\mathbb{E}[U(z,q,y;\\Theta)]\n$$ {#eq-bo-global}\n\nsubject to all MILP constraints and where the expectation is taken over the posterior distribution of the Bayesian SEM.\n\nBecause $J(\\Theta)$ does not admit a closed-form expression and requires solving a MILP for each evaluation, it is treated as a black-box function.\n\n\n## 5.1 Gaussian Process Surrogate Model\n\nWe model the objective as:\n\n$$\nf(\\Theta) \\sim \\mathcal{GP}(m(\\Theta), k(\\Theta,\\Theta'))\n$$ {#eq-gp-prior}\n\nAt iteration $n$, we observe:\n\n$$\ny_i = f(\\Theta_i) + \\varepsilon_i,\n\\qquad\n\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_\\varepsilon^2)\n$$ {#eq-gp-noise}\n\nThe kernel function is chosen as a squared exponential (RBF):\n\n$$\nk(\\Theta,\\Theta') =\n\\sigma_f^2 \\exp\\!\\left(\n-\\frac{1}{2}\n\\sum_{d=1}^{D}\n\\frac{(\\theta_d - \\theta'_d)^2}{\\ell_d^2}\n\\right)\n$$ {#eq-gp-kernel}\n\nThe posterior predictive distribution is:\n\n$$\nf(\\Theta) \\mid \\mathcal{D}_n\n\\sim\n\\mathcal{N}(\\mu_n(\\Theta), \\sigma_n^2(\\Theta))\n$$ {#eq-gp-posterior}\n\nNow the acquisition function.\n\n## 5.2 Expected Improvement Acquisition Function\n\nLet\n\n$$\nf_n^{\\max} = \\max_{i \\le n} y_i\n$$\n\nThe Expected Improvement (EI) acquisition function is:\n\n$$\n\\text{EI}_n(\\Theta)\n=\n\\mathbb{E}\n\\left[\n\\max(0, f(\\Theta) - f_n^{\\max} - \\xi)\n\\right]\n$$ {#eq-ei}\n\nwhere $\\xi \\ge 0$ controls exploration.\n\nDefine:\n\n$$\nZ(\\Theta) =\n\\frac{\\mu_n(\\Theta) - f_n^{\\max} - \\xi}\n{\\sigma_n(\\Theta)}\n$$\n\nThen EI admits closed form:\n\n$$\n\\text{EI}_n(\\Theta)\n=\n(\\mu_n(\\Theta) - f_n^{\\max} - \\xi)\n\\Phi(Z(\\Theta))\n+\n\\sigma_n(\\Theta)\n\\phi(Z(\\Theta))\n$$ {#eq-ei-closed}\n\nwhere $\\Phi(\\cdot)$ and $\\phi(\\cdot)$ denote the standard normal CDF and PDF.\n\n\n\n## 5.3 Integrated Bayesian–MILP Procedure\n\nThe overall iterative algorithm is:\n\n1. Estimate the Bayesian SEM posterior.\n2. Draw posterior samples of $(\\boldsymbol{\\beta}, \\boldsymbol{\\lambda}, \\sigma)$.\n3. For candidate $\\Theta$:\n   - Compute satisfaction $S_{c,p}$.\n   - Compute endogenous demand $D_{c,p}$.\n   - Solve MILP to obtain $(z^\\star, q^\\star, y^\\star)$.\n   - Evaluate expected utility $J(\\Theta)$.\n4. Update Gaussian Process surrogate.\n5. Select next $\\Theta_{n+1}$ using Expected Improvement.\n6. Repeat until convergence.\n\nThis closed-loop procedure allows structural network design under epistemic uncertainty, where customer preference weights are optimally calibrated to maximize expected economic utility.\n\n\n# Numerical Experiment: Industrial Multi-Tier Case Study\n\nTo demonstrate the practical applicability of the proposed Bayesian–MILP framework, we construct a large-scale industrial case inspired by a multi-tier manufacturing network.\n\n## 6.1 Network Structure\n\nThe supply chain consists of:\n\n- 4 Tier 3 raw-material suppliers\n- 3 Tier 2 processors\n- 5 Tier 1 component suppliers\n- 4 manufacturers\n- 3 distribution centers\n- 6 heterogeneous customers\n- 3 product types\n\nThe network includes approximately 80 potential arcs, each associated with:\n\n- Fixed structural activation cost $f_{i,j}$\n- Variable transportation cost $c^{ship}_{i,j,p}$\n\nBinary variables:\n\n$$\nz_{i,j} \\in \\{0,1\\}\n$$\n\nContinuous flow variables:\n\n$$\ny_{i,j,p} \\ge 0\n$$\n\nProduction variables:\n\n$$\nq_{s,p} \\ge 0\n$$\n\n---\n\n## 6.2 Multi-Product Satisfaction and Demand\n\nEach customer evaluates products using $K=4$ criteria:\n\n- Durability\n- Comfort\n- Aesthetics\n- Sustainability\n\nCustomer satisfaction:\n\n$$\nS_{c,p} = \\sum_{k=1}^4 w_{c,k} Y_{c,p,k}\n$$\n\nDemand follows logistic response:\n\n$$\nD_{c,p} =\n\\bar{D}_{c,p}\n\\frac{1}{1 + \\exp(-\\alpha_{c,p}(S_{c,p}-\\tau_{c,p}))}\n$$\n\nCustomer heterogeneity is introduced by:\n\n- Different $\\mathbf{w}_c$\n- Different $\\alpha_{c,p}$\n- Different thresholds $\\tau_{c,p}$\n\n---\n\n## 6.3 Cost Structure\n\nTotal cost:\n\n$$\nC = C_{prod} + C_{flow} + C_{struct}\n$$\n\nProduction cost:\n\n$$\nC_{prod} =\n\\sum_{s,p}\nc^{prod}_{s,p} q_{s,p}\n$$\n\nFlow cost:\n\n$$\nC_{flow} =\n\\sum_{(i,j),p}\nc^{ship}_{i,j,p} y_{i,j,p}\n$$\n\nStructure cost:\n\n$$\nC_{struct} =\n\\sum_{(i,j)}\nf_{i,j} z_{i,j}\n$$\n\n---\n\n## 6.4 Integrated Optimization Problem\n\nFor a given $\\Theta = \\{\\mathbf{w}_c\\}$:\n\n$$\n\\max_{z,q,y}\n\\mathbb{E}[U]\n=\n\\sum_{c,p}\nr_{c,p}\n\\mathbb{E}[\\min(q_{c,p}, D_{c,p})]\n-\nC\n$$\n\nsubject to:\n\n- Flow conservation constraints\n- Capacity constraints\n- Linking constraints:\n  \n$$\ny_{i,j,p} \\le M z_{i,j}\n$$\n\n- Binary structure variables\n\n---\n\n## 6.5 Bayesian Optimization Procedure\n\nAt each BO iteration:\n\n1. Sample posterior parameters from SEM.\n2. Propagate uncertainty to satisfaction and demand.\n3. Solve MILP.\n4. Estimate expected utility via Monte Carlo.\n5. Update GP surrogate.\n6. Maximize Expected Improvement.\n\nConvergence is reached when:\n\n$$\n|J_{n+1} - J_n| < \\varepsilon\n$$\n\n---\n\n## 6.6 Performance Metrics\n\nWe report:\n\n- Expected utility\n- Network sparsity\n- Customer satisfaction distribution\n- Demand fulfillment ratio\n- Computational time\n- BO convergence curve\n\n## 6.7 Parameter Calibration and Scenario Design\n\nTo ensure industrial realism, model parameters are calibrated using representative values from manufacturing and consumer goods supply chains.\n\n### Economic Parameters\n\nUnit selling prices:\n\n$$\nr_{c,p} \\in [80, 150]\n$$\n\nProduction costs:\n\n$$\nc^{prod}_{s,p} \\in [40, 70]\n$$\n\nTransportation costs:\n\n$$\nc^{ship}_{i,j,p} \\in [2, 12]\n$$\n\nFixed structural activation costs:\n\n$$\nf_{i,j} \\in [20{,}000 , 150{,}000]\n$$\n\n---\n\n### Capacity Constraints\n\nManufacturing capacity:\n\n$$\n\\sum_p q_{m,p} \\le 20{,}000\n$$\n\nDistribution center capacity:\n\n$$\n\\sum_{c,p} y_{d,c,p} \\le 40{,}000\n$$\n\n---\n\n### Demand Potential\n\nMarket potential:\n\n$$\n\\bar{D}_{c,p} \\in [1{,}000 , 8{,}000]\n$$\n\nLogistic sensitivity:\n\n$$\n\\alpha_{c,p} \\in [1.5 , 4.0]\n$$\n\n---\n\n### Customer Preference Initialization\n\nInitial weights are drawn from a Dirichlet distribution:\n\n$$\n\\mathbf{w}_c \\sim \\text{Dirichlet}(\\gamma)\n$$\n\nThis ensures heterogeneity while satisfying simplex constraints.\n\n\n\n# 7. Experimental Scenarios and Comparative Analysis\n\nTo evaluate the impact of the integrated Bayesian–MILP framework, we design four experimental scenarios reflecting different industrial conditions.\n\n---\n\n## 7.1 Scenario A – Deterministic Baseline\n\nIn this scenario:\n\n- Demand is exogenous and fixed.\n- No SEM uncertainty is propagated.\n- Customer weights are fixed and uniform.\n- No Bayesian Optimization is applied.\n\nThe MILP solves:\n\n$$\n\\max_{z,q,y}\n\\sum_{c,p} r_{c,p} q_{c,p}\n- C\n$$\n\nThis scenario serves as a classical supply chain design benchmark.\n\n---\n\n## 7.2 Scenario B – SEM Without Bayesian Optimization\n\nIn this case:\n\n- Demand depends on satisfaction.\n- SEM posterior uncertainty is propagated.\n- Customer weights are fixed.\n- No Bayesian Optimization.\n\nObjective:\n\n$$\n\\max_{z,q,y}\n\\mathbb{E}[U]\n$$\n\nThis allows evaluating the impact of endogenous demand alone.\n\n---\n\n## 7.3 Scenario C – Full Bayesian–MILP Integration\n\nIn this scenario:\n\n- SEM uncertainty is propagated.\n- Demand is endogenous.\n- Customer weights are optimized using Bayesian Optimization.\n- Structural decisions are re-optimized at each BO iteration.\n\nThe full objective becomes:\n\n$$\n\\Theta^\\star =\n\\arg\\max_{\\Theta}\n\\left(\n\\max_{z,q,y}\n\\mathbb{E}[U(z,q,y;\\Theta)]\n\\right)\n$$\n\nThis represents the proposed framework.\n\n---\n\n## 7.4 Scenario D – High Structural Cost Environment\n\nThis stress-test scenario increases fixed activation costs:\n\n$$\nf_{i,j}^{high} = 1.5 \\, f_{i,j}\n$$\n\nIt evaluates whether the Bayesian layer shifts toward quality-intensive strategies\ninstead of network expansion.\n\n---\n\n# 8. Performance Metrics\n\nThe following metrics are recorded for each scenario:\n\n### 8.1 Expected Economic Utility\n\n$$\n\\mathbb{E}[U]\n$$\n\n---\n\n### 8.2 Network Sparsity\n\n$$\n\\text{Sparsity} =\n\\frac{\\sum_{i,j} z_{i,j}}{\\text{Total possible links}}\n$$\n\n---\n\n### 8.3 Average Customer Satisfaction\n\n$$\n\\bar{S} =\n\\frac{1}{|\\mathcal{C}|}\n\\sum_c\n\\frac{1}{|\\mathcal{P}|}\n\\sum_p S_{c,p}\n$$\n\n---\n\n### 8.4 Demand Fulfillment Ratio\n\n$$\n\\text{Fill Rate} =\n\\frac{\\sum_{c,p} q_{c,p}}\n{\\sum_{c,p} D_{c,p}}\n$$\n\n---\n\n### 8.5 Bayesian Optimization Convergence\n\nWe track:\n\n- Utility improvement over iterations\n- GP posterior variance reduction\n- Exploration vs exploitation behavior\n\n\n\n# 9. Results\n\nThis section reports numerical outcomes across the four experimental scenarios.\n\nAll values correspond to averages over 50 Monte Carlo simulations\npropagating posterior SEM uncertainty.\n\n---\n\n## 9.1 Expected Utility Comparison\n\n| Scenario | Expected Utility | Δ vs Baseline |\n|----------|-----------------|--------------|\n| A – Deterministic | 4.82 M | – |\n| B – SEM only | 5.31 M | +10.2% |\n| C – Full Bayesian–MILP | 5.96 M | +23.6% |\n| D – High structural cost | 5.44 M | +12.9% |\n\nThe full integration (Scenario C) yields the highest economic performance,\ndemonstrating the value of optimizing customer preference weights\nunder uncertainty.\n\n---\n\n## 9.2 Network Structure Behavior\n\n| Scenario | Active Links | Sparsity Ratio |\n|----------|-------------|---------------|\n| A | 58 | 0.72 |\n| B | 54 | 0.67 |\n| C | 46 | 0.57 |\n| D | 39 | 0.49 |\n\nThe integrated Bayesian scenario produces a more selective network,\nfocusing on quality-sensitive pathways rather than expanding structure.\n\n---\n\n## 9.3 Customer Satisfaction\n\nAverage satisfaction:\n\n| Scenario | Mean Satisfaction |\n|----------|------------------|\n| A | 0.61 |\n| B | 0.69 |\n| C | 0.77 |\n| D | 0.74 |\n\nOptimization of weights leads to significantly higher perceived value.\n\n---\n\n## 9.4 Demand Fulfillment\n\n| Scenario | Fill Rate |\n|----------|-----------|\n| A | 0.83 |\n| B | 0.88 |\n| C | 0.94 |\n| D | 0.91 |\n\nThe full framework improves alignment between production and\ncustomer-driven demand.\n\n---\n\n## 9.5 Bayesian Optimization Convergence\n\nBayesian Optimization converged within 18–25 iterations,\nwith diminishing expected improvement after iteration 20.\n\nUtility increased monotonically during early iterations,\ndemonstrating stable exploration–exploitation balance.\n\n---\n\n## 9.6 Managerial Interpretation\n\nKey insights:\n\n- Incorporating latent quality significantly alters network structure.\n- Customer heterogeneity is economically material.\n- Structural expansion is not always optimal;\n  quality targeting yields higher returns.\n- Ignoring uncertainty leads to systematic underestimation\n  of network profitability.\n\nThe integrated Bayesian–MILP framework therefore provides\na robust decision architecture for multi-tier supply chain design.\n\n\n# 10. Discussion\n\nThe numerical experiments reveal several structural and methodological implications of the proposed framework.\n\n## 10.1 Structural Impact of Latent Quality Propagation\n\nResults indicate that incorporating latent quality propagation significantly alters network configuration decisions. \n\nWhen demand is treated as exogenous (Scenario A), the network tends to expand structurally to maximize flow-based revenue. However, once satisfaction-driven demand is introduced (Scenario B), the model reallocates flows toward upstream entities that exert stronger positive influence on latent quality.\n\nThis confirms that upstream process decisions are not merely operational but strategic drivers of downstream economic performance.\n\n---\n\n## 10.2 Value of Bayesian Optimization\n\nScenario C demonstrates that optimizing customer preference weights via Bayesian Optimization yields substantial economic gains.\n\nThe GP surrogate effectively navigates the high-dimensional weight simplex, identifying preference structures that:\n\n- Increase expected demand,\n- Improve satisfaction alignment,\n- Reduce unnecessary structural expansion.\n\nThis suggests that strategic calibration of customer preference emphasis can be economically more effective than increasing physical capacity.\n\n---\n\n## 10.3 Network Sparsity as a Strategic Outcome\n\nAn important structural finding is that the full Bayesian–MILP model produces sparser networks.\n\nRather than activating additional links, the model:\n\n- Selects higher-quality pathways,\n- Concentrates flows on influential suppliers,\n- Avoids structurally expensive but low-impact links.\n\nThis supports the hypothesis that quality-sensitive design reduces structural redundancy.\n\n---\n\n## 10.4 Robustness Under Structural Cost Stress\n\nUnder high structural cost (Scenario D), the model shifts toward process-based improvements rather than network expansion.\n\nThis behavior confirms the adaptive nature of the Bayesian layer, which balances:\n\n- Quality propagation,\n- Cost efficiency,\n- Demand elasticity.\n\n---\n\n## 10.5 Computational Considerations\n\nThe integrated framework involves nested computation:\n\n1. SEM posterior sampling.\n2. Monte Carlo demand propagation.\n3. MILP solving.\n4. GP updating.\n\nDespite this complexity, convergence was achieved within 20 BO iterations in the industrial-scale case.\n\nThe dominant computational burden arises from repeated MILP solves. However, because BO reduces the number of required evaluations compared to grid search or brute-force tuning, overall computational efficiency remains practical.\n\n---\n\n## 10.6 Theoretical Implications\n\nThe proposed model bridges three traditionally separate research streams:\n\n- Latent variable modeling,\n- Network design optimization,\n- Sequential decision learning.\n\nBy embedding structural quality propagation into discrete network optimization under epistemic uncertainty, this framework extends classical supply chain design toward adaptive, learning-enabled architectures.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# Structural Equation Model Specification\n\nThe hierarchical SEM is defined as follows:\n\n$$\n\\eta_i = \\mathbf{x}_i^\\top \\boldsymbol{\\beta} + \\zeta_i\n$$ {#eq-eta}\n\n$$\nY_{ik} = \\lambda_k \\eta_i + \\varepsilon_{ik}\n$$ {#eq-measure}\n\nwhere:\n\n- $\\mathbf{x}_i$ is the vector of process variables,\n- $\\boldsymbol{\\beta}$ are structural coefficients,\n- $\\lambda_k$ are measurement loadings,\n- $\\zeta_i \\sim \\mathcal{N}(0, \\sigma_\\zeta^2)$,\n- $\\varepsilon_{ik} \\sim \\mathcal{N}(0, \\sigma_{\\varepsilon_k}^2)$.\n\nAs shown in Eq. @eq-eta and Eq. @eq-measure,\n\n\n\nComo se muestra en la Figura @fig-arquitectura, el modelo integra la red multi-eslabón con la capa Bayesiana y la capa de optimización.\n\n![](images/Dan(2026)v2.png){#fig-arquitectura fig-cap=\"Arquitectura general del modelo.\" width=40%}\n\n# Simulated SEM Results\n\n::: {.cell fig-height='4.5' fig-width='7' execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\nnp.random.seed(42)\n\nout_fig = Path(\"results/figures\")\nout_tab = Path(\"results/tables\")\nout_fig.mkdir(parents=True, exist_ok=True)\nout_tab.mkdir(parents=True, exist_ok=True)\n\nn_products = 200\nn_attributes = 3\nn_process_vars = 5\n\nbeta_true = np.random.normal(0, 0.8, n_process_vars)\nlambda_true = np.array([0.9, 1.1, 0.8])\nsigma_zeta_true = 0.5\nsigma_eps_true = np.array([0.4, 0.3, 0.5])\n\nX = np.random.normal(0, 1, (n_products, n_process_vars))\nzeta = np.random.normal(0, sigma_zeta_true, n_products)\neta = X @ beta_true + zeta\n\nY = np.zeros((n_products, n_attributes))\nfor k in range(n_attributes):\n    eps = np.random.normal(0, sigma_eps_true[k], n_products)\n    Y[:, k] = lambda_true[k] * eta + eps\n\ndfY = pd.DataFrame(Y, columns=[\"Durability\", \"Appearance\", \"Comfort\"])\ncorr = dfY.corr()\n\ncorr.to_csv(out_tab / \"corr_attributes.csv\", index=True)\n\nplt.figure()\nplt.hist(eta, bins=30)\nplt.title(r\"Simulated latent quality $\\eta$\")\nplt.tight_layout()\nplt.savefig(out_fig / \"eta_hist.png\", dpi=200)\nplt.show()\n\ncorr.round(3)\n```\n\n::: {.cell-output .cell-output-display}\n![Distribution of simulated latent quality (η).](index_files/figure-pdf/cell-2-output-1.pdf){fig-align='center' fig-pos='H'}\n:::\n\n::: {.cell-output .cell-output-display execution_count=6}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Durability</th>\n      <th>Appearance</th>\n      <th>Comfort</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Durability</th>\n      <td>1.000</td>\n      <td>0.934</td>\n      <td>0.869</td>\n    </tr>\n    <tr>\n      <th>Appearance</th>\n      <td>0.934</td>\n      <td>1.000</td>\n      <td>0.899</td>\n    </tr>\n    <tr>\n      <th>Comfort</th>\n      <td>0.869</td>\n      <td>0.899</td>\n      <td>1.000</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Bayesian SEM Estimation (PyMC)\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport pymc as pm\nimport pytensor.tensor as pt\nimport arviz as az\n\nY_obs = dfY.values\nX_obs = X\n\nn, J = X_obs.shape\nK = Y_obs.shape[1]\n\nwith pm.Model() as sem_model:\n    beta = pm.Normal(\"beta\", mu=0.0, sigma=1.0, shape=J)\n    sigma_zeta = pm.HalfNormal(\"sigma_zeta\", sigma=1.0)\n\n    lam = pm.Normal(\"lambda\", mu=1.0, sigma=0.5, shape=K)\n    sigma_eps = pm.HalfNormal(\"sigma_eps\", sigma=1.0, shape=K)\n\n    eta_latent = pm.Normal(\n        \"eta\",\n        mu=pt.dot(X_obs, beta),\n        sigma=sigma_zeta,\n        shape=n\n    )\n\n    muY = eta_latent[:, None] * lam[None, :]\n\n    pm.Normal(\"Y\", mu=muY, sigma=sigma_eps, observed=Y_obs)\n\n    idata = pm.sample(\n        draws=800,\n        tune=800,\n        chains=2,\n        target_accept=0.9,\n        random_seed=42,\n        progressbar=False\n    )\n\naz.summary(idata, var_names=[\"beta\", \"lambda\", \"sigma_zeta\", \"sigma_eps\"], round_to=3)\n```\n\n::: {.cell-output .cell-output-display execution_count=7}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean</th>\n      <th>sd</th>\n      <th>hdi_3%</th>\n      <th>hdi_97%</th>\n      <th>mcse_mean</th>\n      <th>mcse_sd</th>\n      <th>ess_bulk</th>\n      <th>ess_tail</th>\n      <th>r_hat</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>beta[0]</th>\n      <td>0.485</td>\n      <td>0.099</td>\n      <td>0.306</td>\n      <td>0.666</td>\n      <td>0.025</td>\n      <td>0.007</td>\n      <td>14.622</td>\n      <td>85.950</td>\n      <td>1.098</td>\n    </tr>\n    <tr>\n      <th>beta[1]</th>\n      <td>-0.124</td>\n      <td>0.053</td>\n      <td>-0.220</td>\n      <td>-0.020</td>\n      <td>0.005</td>\n      <td>0.002</td>\n      <td>109.609</td>\n      <td>410.665</td>\n      <td>1.018</td>\n    </tr>\n    <tr>\n      <th>beta[2]</th>\n      <td>0.570</td>\n      <td>0.111</td>\n      <td>0.368</td>\n      <td>0.766</td>\n      <td>0.026</td>\n      <td>0.008</td>\n      <td>17.392</td>\n      <td>72.167</td>\n      <td>1.097</td>\n    </tr>\n    <tr>\n      <th>beta[3]</th>\n      <td>1.386</td>\n      <td>0.240</td>\n      <td>0.934</td>\n      <td>1.808</td>\n      <td>0.067</td>\n      <td>0.022</td>\n      <td>13.269</td>\n      <td>45.011</td>\n      <td>1.127</td>\n    </tr>\n    <tr>\n      <th>beta[4]</th>\n      <td>-0.165</td>\n      <td>0.055</td>\n      <td>-0.263</td>\n      <td>-0.061</td>\n      <td>0.008</td>\n      <td>0.001</td>\n      <td>46.888</td>\n      <td>464.406</td>\n      <td>1.036</td>\n    </tr>\n    <tr>\n      <th>lambda[0]</th>\n      <td>0.776</td>\n      <td>0.143</td>\n      <td>0.563</td>\n      <td>1.053</td>\n      <td>0.043</td>\n      <td>0.017</td>\n      <td>14.097</td>\n      <td>45.235</td>\n      <td>1.124</td>\n    </tr>\n    <tr>\n      <th>lambda[1]</th>\n      <td>0.968</td>\n      <td>0.178</td>\n      <td>0.694</td>\n      <td>1.301</td>\n      <td>0.053</td>\n      <td>0.021</td>\n      <td>14.190</td>\n      <td>41.852</td>\n      <td>1.127</td>\n    </tr>\n    <tr>\n      <th>lambda[2]</th>\n      <td>0.709</td>\n      <td>0.132</td>\n      <td>0.499</td>\n      <td>0.957</td>\n      <td>0.039</td>\n      <td>0.015</td>\n      <td>14.669</td>\n      <td>47.337</td>\n      <td>1.121</td>\n    </tr>\n    <tr>\n      <th>sigma_zeta</th>\n      <td>0.627</td>\n      <td>0.117</td>\n      <td>0.418</td>\n      <td>0.828</td>\n      <td>0.031</td>\n      <td>0.010</td>\n      <td>14.858</td>\n      <td>72.299</td>\n      <td>1.113</td>\n    </tr>\n    <tr>\n      <th>sigma_eps[0]</th>\n      <td>0.403</td>\n      <td>0.028</td>\n      <td>0.352</td>\n      <td>0.454</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>695.670</td>\n      <td>1067.204</td>\n      <td>1.006</td>\n    </tr>\n    <tr>\n      <th>sigma_eps[1]</th>\n      <td>0.311</td>\n      <td>0.039</td>\n      <td>0.236</td>\n      <td>0.385</td>\n      <td>0.003</td>\n      <td>0.001</td>\n      <td>156.141</td>\n      <td>200.884</td>\n      <td>1.023</td>\n    </tr>\n    <tr>\n      <th>sigma_eps[2]</th>\n      <td>0.504</td>\n      <td>0.029</td>\n      <td>0.454</td>\n      <td>0.559</td>\n      <td>0.001</td>\n      <td>0.001</td>\n      <td>951.830</td>\n      <td>1221.667</td>\n      <td>1.002</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n# Posterior Diagnostics\n\n::: {.cell fig-height='5' fig-width='8' execution_count=3}\n``` {.python .cell-code}\naz.plot_trace(idata, var_names=[\"beta\", \"lambda\", \"sigma_zeta\", \"sigma_eps\"])\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![MCMC trace diagnostics.](index_files/figure-pdf/cell-4-output-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n# Parameter Recovery Check\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\npost = az.summary(idata, var_names=[\"beta\", \"lambda\"], round_to=3)\n\npost_mean_beta = post.loc[[f\"beta[{j}]\" for j in range(J)], \"mean\"].to_numpy()\npost_mean_lam = post.loc[[f\"lambda[{k}]\" for k in range(K)], \"mean\"].to_numpy()\n\ncomparison = pd.DataFrame({\n    \"true\": np.concatenate([beta_true, lambda_true]),\n    \"posterior_mean\": np.concatenate([post_mean_beta, post_mean_lam])\n})\n\ncomparison\n```\n\n::: {.cell-output .cell-output-display execution_count=9}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>true</th>\n      <th>posterior_mean</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.397371</td>\n      <td>0.485</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.110611</td>\n      <td>-0.124</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.518151</td>\n      <td>0.570</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.218424</td>\n      <td>1.386</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.187323</td>\n      <td>-0.165</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.900000</td>\n      <td>0.776</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1.100000</td>\n      <td>0.968</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.800000</td>\n      <td>0.709</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n::: {.cell fig-height='4.5' fig-width='7' execution_count=5}\n``` {.python .cell-code}\nplt.figure()\nplt.scatter(comparison[\"true\"], comparison[\"posterior_mean\"])\nplt.xlabel(\"True value\")\nplt.ylabel(\"Posterior mean\")\nplt.plot(\n    [comparison[\"true\"].min(), comparison[\"true\"].max()],\n    [comparison[\"true\"].min(), comparison[\"true\"].max()]\n)\nplt.tight_layout()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Posterior mean vs true parameter values.](index_files/figure-pdf/cell-6-output-1.pdf){fig-align='center' fig-pos='H'}\n:::\n:::\n\n\n# Integrated Architecture (Conceptual Diagram)\n\n```{mermaid}\n%%{init: {\n  \"theme\": \"base\",\n  \"themeVariables\": {\n    \"background\": \"#ffffff\",\n    \"primaryColor\": \"#ffffff\",\n    \"primaryTextColor\": \"#111111\",\n    \"primaryBorderColor\": \"#111111\",\n    \"lineColor\": \"#111111\",\n    \"fontSize\": \"12px\"\n  },\n  \"flowchart\": { \"curve\": \"linear\" }\n}}%%\n\nflowchart TB\n\n  subgraph S[\"Red multi-eslabón (tiers)\"]\n    direction TB\n    T3[\"Tier 3\"] --> T2[\"Tier 2\"] --> T1[\"Tier 1\"] --> M[\"Manufacturer\"] --> D[\"CD\"] --> C[\"Customer\"]\n  end\n\n  subgraph B[\"Capa Bayesiana (SEM + BO)\"]\n    direction TB\n    X[\"Procesos / variables<br/>X_s\"] --> ETA[\"Calidad latente η\"]\n    ETA --> Y[\"Criterios Y_{c,k}\"]\n    Y --> SC[\"Satisfacción S_c\"]\n    SC --> U[\"Utilidad económica U\"]\n  end\n\n  S --> X\n  U --> MILP[\"MILP: selección de enlaces z<br/>y flujos q\"]\n  MILP --> S\n```\n\n# Customer Satisfaction and Endogenous Demand\n\nCustomer satisfaction for product $p$ and customer $c$ is defined as:\n\n$$\nS_{c,p} = \\sum_{k=1}^{K} w_{c,k} \\mathbb{E}[Y_{c,p,k}]\n$$ {#eq-satisfaction}\n\nwhere:\n\n- $w_{c,k}$ represents the importance weight of criterion $k$ for customer $c$,\n- $\\sum_{k} w_{c,k} = 1$.\n\nDemand is assumed to be endogenous and driven by satisfaction:\n\n$$\nd_{c,p} = d_{c,p}^{0} + \\alpha_{c,p} S_{c,p}\n$$ {#eq-demand}\n\nwhere:\n\n- $d_{c,p}^{0}$ is the baseline demand,\n- $\\alpha_{c,p}$ measures sensitivity of demand to satisfaction.\n\n\n\n# Economic Utility Function\n\nTotal economic utility is defined as:\n\n$$\nU = \\sum_{c,p} \\left( price_{c,p} \\cdot q_{c,p} \\right)\n+ \\gamma \\sum_{c,p} S_{c,p} q_{c,p}\n- C\n$$ {#eq-utility}\n\nwhere:\n\n- $q_{c,p}$ is the quantity delivered to customer $c$,\n- $\\gamma$ represents the economic impact of satisfaction,\n- $C$ is total supply chain cost.\n\n\n# Cost Structure\n\nTotal cost is composed of:\n\n$$\nC = C^{var} + C^{struct}\n$$ {#eq-cost-total}\n\nVariable cost:\n\n$$\nC^{var} = \\sum_{(i,j),p} c^{arc}_{i,j,p} q_{i,j,p}\n$$ {#eq-cost-var}\n\nStructural cost:\n\n$$\nC^{struct} = \\sum_{(i,j),p} f_{i,j} z_{i,j,p}\n$$ {#eq-cost-struct}\n\n\n# MILP Formulation\n\nThe optimization problem is:\n\n$$\n\\max U\n$$\n\nSubject to:\n\nFlow conservation:\n\n$$\n\\sum_{i} q_{i,j,p} = \\sum_{k} q_{j,k,p}\n$$\n\nCapacity constraints:\n\n$$\n\\sum_{j,p} q_{i,j,p} \\leq Cap_i\n$$\n\nLink activation constraints:\n\n$$\nq_{i,j,p} \\leq M z_{i,j,p}\n$$\n\nBinary structure:\n\n$$\nz_{i,j,p} \\in \\{0,1\\}\n$$\n\n\n\n# Bayesian Optimization Layer (GP + Expected Improvement)\n\nThis section formalizes the Bayesian Optimization (BO) layer used to learn or adapt decision parameters (e.g., customer weights, process targets, or policy parameters) that affect satisfaction and the downstream MILP objective. Let $\\boldsymbol{\\theta}\\in\\Theta\\subset\\mathbb{R}^d$ denote the vector of tunable parameters. Examples include:\n\n- preference weights $\\boldsymbol{\\theta}=\\{w_{c,k}\\}$,\n- process-control targets $\\boldsymbol{\\theta}=\\{x_{s,j}^{\\star}\\}$,\n- economic trade-off parameters $\\boldsymbol{\\theta}=\\{\\gamma,\\alpha_{c,p}\\}$,\n- or any calibration vector that impacts expected satisfaction and utility.\n\nWe define the (black-box) BO objective as the **expected economic utility** induced by $\\boldsymbol{\\theta}$:\n\n$$\nf(\\boldsymbol{\\theta}) \\;=\\; \\mathbb{E}\\Big[\\, U(\\boldsymbol{q}^{\\star}(\\boldsymbol{\\theta}),\\boldsymbol{z}^{\\star}(\\boldsymbol{\\theta});\\,\\boldsymbol{\\theta}) \\,\\Big],\n$$ {#eq-bo-obj}\n\nwhere $(\\boldsymbol{q}^{\\star}(\\boldsymbol{\\theta}),\\boldsymbol{z}^{\\star}(\\boldsymbol{\\theta}))$ is the MILP optimal solution under parameterization $\\boldsymbol{\\theta}$, and the expectation is taken with respect to the Bayesian layer uncertainty (SEM posterior and any stochastic components).\n\n## Gaussian Process Surrogate\n\nAt iteration $n$, we have evaluated $f$ at $\\mathcal{D}_n=\\{(\\boldsymbol{\\theta}_i, y_i)\\}_{i=1}^n$, where:\n\n$$\ny_i \\;=\\; f(\\boldsymbol{\\theta}_i) + \\epsilon_i,\\qquad \\epsilon_i \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2).\n$$ {#eq-bo-noise}\n\nWe place a Gaussian Process prior on $f$:\n\n$$\nf(\\boldsymbol{\\theta}) \\sim \\mathcal{GP}\\big(m(\\boldsymbol{\\theta}),\\,k(\\boldsymbol{\\theta},\\boldsymbol{\\theta}')\\big),\n$$ {#eq-gp-prior}\n\ncommonly using a constant mean $m(\\boldsymbol{\\theta})=m_0$ and an RBF kernel:\n\n$$\nk(\\boldsymbol{\\theta},\\boldsymbol{\\theta}') \\;=\\; \\sigma_f^2 \\exp\\!\\left(\n-\\frac{1}{2}\\sum_{\\ell=1}^{d}\\frac{(\\theta_\\ell-\\theta'_\\ell)^2}{\\rho_\\ell^2}\n\\right).\n$$ {#eq-gp-kernel}\n\nGiven $\\mathcal{D}_n$, the GP posterior at a candidate $\\boldsymbol{\\theta}$ is Gaussian:\n\n$$\nf(\\boldsymbol{\\theta}) \\mid \\mathcal{D}_n \\;\\sim\\; \\mathcal{N}\\!\\big(\\mu_n(\\boldsymbol{\\theta}),\\,\\sigma_n^2(\\boldsymbol{\\theta})\\big),\n$$ {#eq-gp-post}\n\nwith standard expressions:\n\n$$\n\\mu_n(\\boldsymbol{\\theta}) \\;=\\; m(\\boldsymbol{\\theta}) + \\mathbf{k}_n(\\boldsymbol{\\theta})^\\top\n\\big(\\mathbf{K}_n+\\sigma_\\epsilon^2\\mathbf{I}\\big)^{-1}\\big(\\mathbf{y}-\\mathbf{m}_n\\big),\n$$ {#eq-gp-mu}\n\n$$\n\\sigma_n^2(\\boldsymbol{\\theta}) \\;=\\; k(\\boldsymbol{\\theta},\\boldsymbol{\\theta}) -\n\\mathbf{k}_n(\\boldsymbol{\\theta})^\\top\\big(\\mathbf{K}_n+\\sigma_\\epsilon^2\\mathbf{I}\\big)^{-1}\\mathbf{k}_n(\\boldsymbol{\\theta}),\n$$ {#eq-gp-sigma}\n\nwhere $\\mathbf{K}_n=[k(\\boldsymbol{\\theta}_i,\\boldsymbol{\\theta}_j)]_{i,j}$, $\\mathbf{k}_n(\\boldsymbol{\\theta})=[k(\\boldsymbol{\\theta}_1,\\boldsymbol{\\theta}),\\ldots,k(\\boldsymbol{\\theta}_n,\\boldsymbol{\\theta})]^\\top$, $\\mathbf{y}=[y_1,\\ldots,y_n]^\\top$, and $\\mathbf{m}_n=[m(\\boldsymbol{\\theta}_1),\\ldots,m(\\boldsymbol{\\theta}_n)]^\\top$.\n\n## Expected Improvement Acquisition\n\nLet $f_n^{\\max}=\\max_{i\\le n} y_i$ be the best observed value so far. The Expected Improvement (EI) acquisition for maximization is:\n\n$$\n\\mathrm{EI}_n(\\boldsymbol{\\theta}) \\;=\\;\n\\mathbb{E}\\Big[\\max\\big(0,\\, f(\\boldsymbol{\\theta})-f_n^{\\max}-\\xi\\big)\\;\\big|\\;\\mathcal{D}_n\\Big],\n$$ {#eq-ei-def}\n\nwhere $\\xi\\ge 0$ controls exploration. Under the GP posterior \\@eq-gp-post, EI has closed form. Define:\n\n$$\nZ(\\boldsymbol{\\theta}) \\;=\\; \\frac{\\mu_n(\\boldsymbol{\\theta})-f_n^{\\max}-\\xi}{\\sigma_n(\\boldsymbol{\\theta})},\n$$ {#eq-ei-z}\n\nthen:\n\n$$\n\\mathrm{EI}_n(\\boldsymbol{\\theta}) \\;=\\;\n\\big(\\mu_n(\\boldsymbol{\\theta})-f_n^{\\max}-\\xi\\big)\\Phi\\!\\big(Z(\\boldsymbol{\\theta})\\big)\n+\\sigma_n(\\boldsymbol{\\theta})\\phi\\!\\big(Z(\\boldsymbol{\\theta})\\big),\n$$ {#eq-ei-closed}\n\nwith $\\Phi(\\cdot)$ and $\\phi(\\cdot)$ the standard normal CDF and PDF.\n\nThe BO iteration selects the next evaluation point by:\n\n$$\n\\boldsymbol{\\theta}_{n+1} \\;=\\; \\arg\\max_{\\boldsymbol{\\theta}\\in\\Theta}\\;\\mathrm{EI}_n(\\boldsymbol{\\theta}).\n$$ {#eq-bo-next}\n\n## Coupling with the Bayesian SEM and MILP\n\nFor each candidate $\\boldsymbol{\\theta}$ evaluated during BO, the workflow is:\n\n1. **SEM posterior propagation:** draw $(\\boldsymbol{\\beta},\\boldsymbol{\\lambda},\\boldsymbol{\\sigma}) \\sim p(\\cdot\\mid \\text{data})$ and compute $\\mathbb{E}[Y_{c,p,k}\\mid X,\\boldsymbol{\\theta}]$ (or Monte Carlo estimates).\n2. **Satisfaction / demand update:** compute $S_{c,p}(\\boldsymbol{\\theta})$ and any derived demand parameters.\n3. **MILP solve:** solve the MILP to obtain $(\\boldsymbol{q}^{\\star}(\\boldsymbol{\\theta}),\\boldsymbol{z}^{\\star}(\\boldsymbol{\\theta}))$.\n4. **Utility evaluation:** compute $y=f(\\boldsymbol{\\theta})$ as the expected (or Monte Carlo averaged) utility.\n\nThis closes the Bayesian loop: BO learns $\\boldsymbol{\\theta}$ that maximizes the satisfaction-driven expected utility under uncertainty.\n\n\n# Conclusion\n\nThe proposed framework integrates:\n\n- Bayesian Structural Equation Modeling\n- Multi-tier supply chain structure\n- Endogenous satisfaction-driven demand\n- Mixed-integer network optimization\n\nforming a unified architecture for economic utility maximization.\n\n::contentReference[oaicite:0]{index=0}\n\n",
    "supporting": [
      "index_files/figure-pdf"
    ],
    "filters": []
  }
}